{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3e84ec6b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H(x) = w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = torch.FloatTensor(\n",
    "    [\n",
    "        [73],\n",
    "        [93],\n",
    "        [89],\n",
    "        [96],\n",
    "        [73],\n",
    "    ]\n",
    ")\n",
    "x2_train = torch.FloatTensor(\n",
    "    [\n",
    "        [80],\n",
    "        [88],\n",
    "        [91],\n",
    "        [98],\n",
    "        [66],\n",
    "    ]\n",
    ")\n",
    "x3_train = torch.FloatTensor(\n",
    "    [\n",
    "        [75],\n",
    "        [93],\n",
    "        [90],\n",
    "        [100],\n",
    "        [70],\n",
    "    ]\n",
    ")\n",
    "y_train = torch.FloatTensor(\n",
    "    [\n",
    "        [152],\n",
    "        [185],\n",
    "        [180],\n",
    "        [196],\n",
    "        [142],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치, 편향 초기화\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0/1000 w1 : 0.718 w2 : 0.612 w3 : 0.680 b : 0.009 Cost : 1.079\n",
      "Epoch :  100/1000 w1 : 0.722 w2 : 0.608 w3 : 0.680 b : 0.009 Cost : 1.038\n",
      "Epoch :  200/1000 w1 : 0.727 w2 : 0.603 w3 : 0.681 b : 0.010 Cost : 1.000\n",
      "Epoch :  300/1000 w1 : 0.731 w2 : 0.599 w3 : 0.681 b : 0.010 Cost : 0.963\n",
      "Epoch :  400/1000 w1 : 0.735 w2 : 0.595 w3 : 0.681 b : 0.010 Cost : 0.928\n",
      "Epoch :  500/1000 w1 : 0.739 w2 : 0.590 w3 : 0.681 b : 0.010 Cost : 0.895\n",
      "Epoch :  600/1000 w1 : 0.743 w2 : 0.586 w3 : 0.682 b : 0.010 Cost : 0.864\n",
      "Epoch :  700/1000 w1 : 0.746 w2 : 0.582 w3 : 0.682 b : 0.010 Cost : 0.834\n",
      "Epoch :  800/1000 w1 : 0.750 w2 : 0.579 w3 : 0.682 b : 0.010 Cost : 0.806\n",
      "Epoch :  900/1000 w1 : 0.754 w2 : 0.575 w3 : 0.682 b : 0.010 Cost : 0.779\n",
      "Epoch : 1000/1000 w1 : 0.757 w2 : 0.571 w3 : 0.682 b : 0.011 Cost : 0.754\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch : {epoch:4d}/{nb_epochs} w1 : {w1.item():.3f} w2 : {w2.item():.3f} w3 : {w3.item():.3f} b : {b.item():.3f} Cost : {cost.item():.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적\n",
    "- 행렬의 곱셈 과정에서 이루어지는 벡터 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H(X) = XW (H(X) = w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플\n",
    "- 전체 훈련 데이터의 개수를 셀 수 있는 1개의 단위\n",
    "\n",
    "### 특성 (feature)\n",
    "- y를 결정하게 하는 각각의 독립 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# x_train에 모든 샘플 전부 선언 (5 * 3 행렬)\n",
    "x_train = torch.FloatTensor(\n",
    "    [[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]]\n",
    ")\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 행렬의 곱셈이 성립되려면 좌측 행렬의 열의 크기와 우측 행렬의 행의 크기가 일치해야함\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = x_train.matmul(W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0/20 hypothesis : tensor([0., 0., 0., 0., 0.]) Cost : 29661.800781\n",
      "Epoch :    1/20 hypothesis : tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost : 9537.694336\n",
      "Epoch :    2/20 hypothesis : tensor([104.5421, 125.6208, 119.2478, 134.7861,  95.8280]) Cost : 3069.590820\n",
      "Epoch :    3/20 hypothesis : tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost : 990.670288\n",
      "Epoch :    4/20 hypothesis : tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost : 322.481964\n",
      "Epoch :    5/20 hypothesis : tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost : 107.717064\n",
      "Epoch :    6/20 hypothesis : tensor([148.9423, 178.9731, 169.8976, 192.0301, 136.5279]) Cost : 38.687401\n",
      "Epoch :    7/20 hypothesis : tensor([151.1574, 181.6347, 172.4254, 194.8856, 138.5585]) Cost : 16.499046\n",
      "Epoch :    8/20 hypothesis : tensor([152.4131, 183.1435, 173.8590, 196.5042, 139.7097]) Cost : 9.365656\n",
      "Epoch :    9/20 hypothesis : tensor([153.1250, 183.9988, 174.6723, 197.4216, 140.3625]) Cost : 7.071105\n",
      "Epoch :   10/20 hypothesis : tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost : 6.331867\n",
      "Epoch :   11/20 hypothesis : tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost : 6.092532\n",
      "Epoch :   12/20 hypothesis : tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0614]) Cost : 6.013823\n",
      "Epoch :   13/20 hypothesis : tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost : 5.986775\n",
      "Epoch :   14/20 hypothesis : tensor([154.0017, 185.0517, 175.6785, 198.5501, 141.1671]) Cost : 5.976314\n",
      "Epoch :   15/20 hypothesis : tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost : 5.971213\n",
      "Epoch :   16/20 hypothesis : tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost : 5.967797\n",
      "Epoch :   17/20 hypothesis : tensor([154.0459, 185.1045, 175.7326, 198.6058, 141.2082]) Cost : 5.964961\n",
      "Epoch :   18/20 hypothesis : tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost : 5.962292\n",
      "Epoch :   19/20 hypothesis : tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost : 5.959693\n",
      "Epoch :   20/20 hypothesis : tensor([154.0536, 185.1134, 175.7451, 198.6146, 141.2158]) Cost : 5.957091\n"
     ]
    }
   ],
   "source": [
    "# 전체 코드\n",
    "x_train = torch.FloatTensor(\n",
    "    [[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]]\n",
    ")\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 가중치, 편향\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해짐\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch:4d}/{nb_epochs} hypothesis : {hypothesis.squeeze().detach()} Cost : {cost.item():6f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL_ml_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
